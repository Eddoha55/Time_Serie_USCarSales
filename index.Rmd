---
title: "Time Series Analysis & Forecasting"
author: '[Leonard Henriquez](https://github.com/leonard-henriquez/), Adrien Lequiller & Eddy Ohayon'
date: "`r Sys.Date()`"
output: pdf_document
always_allow_html: yes
---

The full repository (including dataset) is available [here](https://github.com/leonard-henriquez/car_sales)

```{r message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, warning=FALSE)
library(plotly)
library(zoo)
seed <- 31
```

```{r}
mydata=read.csv("input/TOTALNSA.csv",header=T,dec=".")

TOTALNSA.ts=ts(mydata$TOTALNSA,frequency=12,c(1976,1))
df <- data.frame(date=as.Date(as.yearmon(time(TOTALNSA.ts))), values = melt(TOTALNSA.ts)$value)

title  <- "Total Vehicle Sales in thousands of units over months"
x.axis <- "Months"
y.axis <- "Total Vehicle Sales (in thousands of units)"

plot.serie = function(df) {
  plot_ly(df, x=~date) %>%
  add_trace(y = ~values, mode = 'lines') %>%
  layout(title = title,
       xaxis = list(title = x.axis),
       yaxis = list(title = y.axis))
}

plot.serie(df)

#there is clear growing trend but with period of crisis
```
```{r}
monthplot.serie <- function(df) {
  df$month <- factor(month(df$date), levels=1:12, labels=month.abb, ordered=TRUE)
  df$year  <- year(df$date)
  
  hline.data <- ddply(df, .(month), summarize, avgvalue=mean(values))
  head(hline.data)
  
  plot <- ggplot() + 
    geom_line(aes(x=year, y=values, group=month), data=df) +
    geom_hline(aes(yintercept=avgvalue), data=hline.data) +
    facet_grid(~month) +
    theme(
      axis.title.x=element_blank(),
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())
  ggplotly(plot)
}

monthplot.serie(df)

```

```{r}
#maybe we could start a new dataset from 2007-2008 for better predictions

monthplot(TOTALNSA.ts)
#saisonnalitÃ©

```

```{r}
y1= diff(TOTALNSA.ts,lag=12)
plot(y1)
#mauvais 
```

```{r}
y2= diff(log(TOTALNSA.ts),lag=12)
plot(y2)
#mauvais 
```

```{r}
y3=diff(TOTALNSA.ts)
plot(y3)
#pas mal
```

```{r}
y4=diff(diff(TOTALNSA.ts,lag=12))
plot(y4)
#pas mal aussi
```

```{r}
acf(y3) 
pacf(y3)
```

```{r}
acf(y4)
pacf(y4)

#MA(1)
#AR(++)
#go first on ARMA(1,1)
```

```{r}
model1<- arima(TOTALNSA.ts, order = c(0,1,1),seasonal=c(0,1,0))
model1
acf(model1$residuals) 
Box.test(model1$residuals, lag = 15, type="Ljung-Box")
#fonctionne pas
```

```{r}
model2<- arima(TOTALNSA.ts, order = c(2,1,2),seasonal=c(2,1,2))
model2
acf(model2$residuals) 
Box.test(model2$residuals, lag = 15, type="Ljung-Box")

#semble etre le plus court et le meilleur apres plusieurs tests
```

```{r}
myforecast<-predict(model2,n.ahead=5)
point.forecast<-myforecast$pred
SE<-myforecast$se
lower<-point.forecast-qnorm(0.975)*SE
upper<-point.forecast+qnorm(0.975)*SE
plot(TOTALNSA.ts,xlim=c(2000,2019))
# we adjust the scale of the axes to get a nicer plot
lines(point.forecast,col="red")
lines(lower,col="blue")
lines(upper,col="blue")
```


```{r}
#winddow : remoe the crisis - we have enough data
TOTALNSA.ts.2=window(TOTALNSA.ts,start=c(2010,1)) 
plot(TOTALNSA.ts.2)
```

```{r}
monthplot(TOTALNSA.ts.2)
#still clearly seasonlity
```

```{r}
y1.2=diff(TOTALNSA.ts.2,lag=12)
plot(y1.2)
```

```{r}
y2.2=diff(diff(log(TOTALNSA.ts.2),lag=12))
plot(y2.2)
#stationnary 
```

```{r}
acf(y2.2)
pacf(y2.2)
```

```{r}
model1.2<- arima(log(TOTALNSA.ts.2), order = c(0,1,1),seasonal=c(0,1,0))
model1.2
acf(model1.2$residuals) 
Box.test(model1.2$residuals, lag = 15, type="Ljung-Box")
##MA(1)
```

```{r}
model2.2<- arima(log(TOTALNSA.ts.2), order = c(1,1,1),seasonal=c(0,1,0))
model2.2
acf(model2.2$residuals) 
Box.test(model2.2$residuals, lag = 15, type="Ljung-Box")
#works also
```

```{r}
model3.2<- arima(log(TOTALNSA.ts.2), order = c(0,1,2),seasonal=c(0,1,0))
model3.2
acf(model3.2$residuals) 
Box.test(model3.2$residuals, lag = 15, type="Ljung-Box")
#il vaut mieux garder une AR(1) aussi du coup
```

```{r}
model4.2<- arima(log(TOTALNSA.ts.2), order = c(1,1,2),seasonal=c(0,1,0))
model4.2
acf(model4.2$residuals) 
Box.test(model4.2$residuals, lag = 15, type="Ljung-Box")
```

```{r}
AIC(model1.2) 
AIC(model2.2)
# model 1 is better according to AIC
BIC(model1.2) 
BIC(model2.2)
#model 1 is better

##AIC and BIC take the model complexity in account 
```

```{r}
y<-log(TOTALNSA.ts.2)
S=round(0.75*length(y))
h=1
error1.h<-c()
for (i in S:(length(y)-h))
{
  mymodel.sub<-arima(y[1:i], order = c(0,1,1),seasonal = c(0,1,0))
# mymodel.sub<-arima(y[(i-S+1):i], order = c(3,1,0)) moving window
  predict.h<-predict(mymodel.sub,n.ahead=h)$pred[h]
  error1.h<-c(error1.h,y[i+h]-predict.h)
}

error2.h<-c()
for (i in S:(length(y)-h))
{
  mymodel.sub<-arima(y[1:i], order = c(1,1,1),seasonal=c(0,1,0))
  predict.h<-predict(mymodel.sub,n.ahead=h)$pred[h]
  error2.h<-c(error2.h,y[i+h]-predict.h)
}

boxplot(error1.h,error2.h)
```

```{r}
MAE1<-mean(abs(error1.h));MAE1
MAE2<-mean(abs(error2.h));MAE2
# Model 1 has a smaller Mean Absolute Error
MSE1<-mean(abs(error1.h)^2);MSE1
MSE2<-mean(abs(error2.h)^2);MSE2
```

```{r}
library(forecast)
dm.test(error1.h,error2.h,h=h,power=1) 
# no significant difference between MAE1 and MAE2
dm.test(error1.h,error2.h,h=h,power=2) 
# no significant difference between MSE1 and MSE2

## A possibility would be to work with both and AVERAGE!

#let's do MAPE
rerror1.h=error1.h/y[(S+h):length(y)]
rerror2.h=error2.h/y[(S+h):length(y)]

MAPE1=mean(abs(rerror1.h));MAPE1
MAPE2=mean(abs(rerror2.h));MAPE2
dm.test(rerror1.h,rerror2.h,h=h,power=1) 
```

